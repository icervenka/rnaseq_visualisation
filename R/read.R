# TODO unify the reading functions parameter names and inside variables

#' Upgrade of addFeatures from cummeRbund package
#'
#' It was using some deprected function
#'
#' @param object aaa
#' @param features bbb
#' @param level ccc
#' @param ... ddd
#'
#' @return dbi
#'
#' @examples
.addFeatures <- function(object, features, level = "genes", ...) { # nolint
  if (!is.data.frame(features)) {
    stop("features must be a data.frame")
  }
  colnames(features)[1] <- methods::slot(object, level)@idField
  colnames(features) <- DBI::make.db.names(object@DB,
    colnames(features),
    unique = TRUE
  )
  DBI::dbWriteTable(object@DB,
    methods::slot(object, level)@tables$featureTable,
    features,
    row.names = FALSE,
    overwrite = TRUE
  )
  indexQuery <- paste( # nolint
    "CREATE INDEX ",
    methods::slot(object, level)@idField,
    " ON ",
    methods::slot(object, level)@tables$featureTable,
    " (",
    methods::slot(object, level)@idField,
    ")",
    sep = ""
  )
  res <- DBI::dbExecute(object@DB, indexQuery)
}
# TODO fix
# setMethod("addFeatures", signature(object = "CuffSet"), .addFeatures)

# user defined reading functions -----------------------------------------------

#' Universal wrapper for reading tabular text data
#'
#' Determines the correct function for reading based on extension
#' (csv, tsv, txt).
#'
#' @param filename character string, filename with tabular data to read.
#'
#' @return data frame
#' @export
#'
#' @examples
read_data <- function(filename) {
  ext <- tools::file_ext(filename)
  if (ext %in% c("tsv", "txt")) {
    separator <- "\t"
  } else if (ext %in% c("csv")) {
    separator <- ","
  }
  df <- readr::read_delim(filename,
    delim = separator,
    col_names = TRUE,
    escape_double = FALSE,
    trim_ws = TRUE
  )
  return(df)
}

#' Read cufdiff data
#'
#' @param dir character string, directory path that contains cuffdiff data.
#'
#' @return data frame
#' @export
#'
#' @examples
read_data_cuffdiff <- function(dir) {
  cuff <- cummeRbund::readCufflinks(dir)
  annot <- utils::read.delim(paste0(dir, "/gene_exp.diff"),
    sep = "\t",
    header = TRUE,
    na.string = "-"
  ) %>%
    dplyr::select(gene_id, gene)
  cummeRbund::addFeatures(cuff, annot, level = "genes")

  # munging of differential expression data
  diff <- cummeRbund::diffData(cummeRbund::genes(cuff)) %>%
    tibble::as_tibble()
  diff <- diff %>%
    dplyr::filter(value_1 > 0 & value_2 > 0) %>%
    dplyr::filter(status == "OK")
  diff <- diff %>%
    dplyr::mutate(comparison = paste0(sample_1, "_", sample_2)) %>%
    dplyr::left_join(annot %>% unique())
  return(diff)
}

# TODO needs fix
#' Read pathways generated by clusterprofiler_reports_snakemake
#'
#' See https://github.com/icervenka/clusterprofiler_reports_snakemake for more
#' information
#'
#' @param filename character string, text file with clusterProfiler
#' pathways to process
#' @param rank_by which column should the data be ranked on, supplied as
#' variable. default: `GeneRatio/NES`
#' @param descending logical, whethere the renking should be from highest to
#' lowest
#'
#' @return data frame
#' @export
#'
#' @examples
read_pathways_cp <- function(filename,
                             rank_by = `GeneRatio/NES`,
                             descending = TRUE) {
  cp_unified_colnames <- c(
    "ID", "Description", "GeneRatio/NES", "pvalue",
    "p.adjust", "SYMBOL", "ENTREZID", "log2FoldChange"
  )

  df <- read_data(filename) %>%
    stats::setNames(cp_unified_colnames) %>%
    dplyr::mutate(ID = as.character(ID)) %>%
    # TODO might not reflect actual columns, check with cp reports package
    dplyr::select(-SYMBOL, -ENTREZID, -log2FoldChange) %>%
    unique()
  return(df)
}

#' Batch read files from  clusterprofiler_reports_snakemake into one data frame
#'
#' @param dir character string, directory path where the
#' result files are located.
#' @param pattern character string, regex pattern for filenames to include.
#' @param pval_threshold double, p-value significance threshold fo filtering
#' pathways
#' @param recursive logical, whether directories should be scanned recursively
#' for pathway files. default: TRUE
#'
#' @importFrom magrittr %>%
#'
#' @return data frame
#' @export
#'
#' @examples
collate_pathways_cp <- function(dir,
                                pattern = "",
                                pval_threshold = 0.05,
                                recursive = TRUE) {
  pathway_files <- list.files(dir,
    pattern = pattern,
    full.names = FALSE,
    recursive = recursive
  )

  diffexp_pathways <- purrr::map_dfr(pathway_files, function(x) {
    read_pathways_cp(x)
  }) %>%
    dplyr::filter(p.adjust < pval_threshold)
  return(diffexp_pathways)
}

#' Recursively find GSEA result files in a directory
#'
#' @param dir character string, directory path where the result files are
#' located.
#' @param pattern character string, regex pattern restricting time file names
#' that will be processed.
#' @param recursive logical, whether directories should be scanned recursively
#' for pathway files. default: TRUE
#'
#' @return data frame containg the locations of result files and their paths
#' @export
#'
#' @importFrom magrittr %>%
#'
#' @examples
get_gsea_files_from_dir <- function(dir, pattern, recursive = TRUE) {
  file_df <- data.frame(full_path = dir(dir,
    pattern = paste0(pattern, ".*tsv"),
    full.names = TRUE,
    recursive = recursive
  )) %>%
    tidyr::separate(full_path,
      into = c("path", "file"),
      sep = paste0("/", pattern),
      remove = FALSE
    ) %>%
    dplyr::mutate(file = paste0(pattern, file))
  return(file_df)
}

#' Read GSEA result file
#'
#' Adds a filename column containing the filename parameter.
#'
#' @param filename character string, text file with GSEA pathways to process
#' @param rank_by which column should the data be ranked on, supplied as
#' variable. default: NES
#' @param descending logical, whethere the renking should be from highest to
#' lowest
#' @param rename_columns character vector of size 11, new names for data frame
#' columns. Applied as a last operation. default: c("name", "link", "details",
#' "size", "es", "nes", "nom_pval", "fdr_qval", "fwer_pval", "rank_at_max",
#' "leading_edge")
#'
#' @return data frame
#' @export
#'
#' @importFrom magrittr %>%
#'
#' @examples
read_pathways_gsea <- function(filename,
                               rank_by = NES,
                               descending = TRUE,
                               rename_columns = c(
                                 "name", "link", "details", "size", "es", "nes",
                                 "nom_pval", "fdr_qval", "fwer_pval",
                                 "rank_at_max", "leading_edge"
                               )) {
  orientation <- rank_how(descending)

  df <- utils::read.table(filename, header = TRUE, sep = "\t") %>%
    dplyr::select(-X) %>%
    dplyr::mutate(file = filename) %>%
    dplyr::arrange(orientation(abs({{ rank_by }}))) %>%
    dplyr::mutate(pathway_rank = dplyr::row_number()) %>%
    # small e is added to avoid problems in volcano plots with log transforms
    dplyr::mutate(`NOM p-val` = `NOM p-val` + 0.00001) %>%
    dplyr::mutate(`FDR q-val` = `FDR q-val` + 0.00001) %>%
    stats::setNames(rename_columns)
  return(df)
}

#' Batch read GSEA files into one data frame
#'
#' Combines get_gsea_files_from_dir, read_pathways_gsea and filter_pathways
#' functions and sets the column and threshold defaults.
#'
#' @param dir character string, directory with GSEA results to process. Will be
#' processed recursively. default: . (current directory)
#' @param pattern character string, regex pattern for filenames to include.
#' default: gsea_report_for
#' @param score_column name of score column, supplied as variable. default: nes
#' @param score_threshold double, return data subset that pass the score
#' threshold. Will compare the threshold against absolute values from score
#' column. default: 0
#' @param pvalue_column name of p-value column, supplied as variable. default:
#' fdr_qval
#' @param pvalue_threshold double, return data subset that pass the p-value
#' threshold.
#' @param rank_by which column to rank the data on, supplied as variable.
#' default: nes
#' @param recursive logical, whether directories should be scanned recursively
#' for pathway files. default: TRUE
#'
#' @return data frame with parsed GSEA data
#' @export
#'
#' @importFrom magrittr %>%
#'
#' @examples
collate_pathways_gsea <- function(dir,
                                  pattern = "gsea_report_for",
                                  score_column = nes,
                                  score_threshold = 0,
                                  pvalue_column = fdr_qval,
                                  pvalue_threshold = 0.05,
                                  rank_by = nes,
                                  recursive = TRUE) {
  # read the data frame of files
  files_df <- get_gsea_files_from_dir(dir, pattern, recursive = recursive)

  # process files
  purrr::map_dfr(unique(files_df$path), function(x) {
    filtered_df <- files_df %>%
      dplyr::filter(path == x)
    purrr::map_dfr(filtered_df$file, function(y) {
      read_pathways_gsea(paste0(x, "/", y))
    }) %>%
      filter_pathways(
        score_column = score_column,
        pvalue_column = pvalue_column,
        rank_by = rank_by,
        score_threshold = score_threshold,
        pvalue_threshold = pvalue_threshold
      )
  })
}

#' Read analysis file from ipa_reports_snakemake
#'
#' @param filename character string, text file with IPA pathways to process
#' @param rank_by which column to rank the data on, supplied as variable.
#' default: zscore
#' @param descending logical, whether ranking should be done from highest to
#' lowest value. default: TRUE
#'
#' @return data frame
#' @export
#'
#' @importFrom magrittr %>%
#'
#' @examples
read_pathways_ipa <- function(filename, rank_by = zscore, descending = TRUE) {
  orientation <- rank_how(descending)

  utils::read.table(filename, header = TRUE, sep = "\t") %>%
    dplyr::arrange(orientation(abs({{ rank_by }}))) %>%
    dplyr::mutate(pathway_rank = dplyr::row_number())
}

#' Batch read IPA files into one data frame
#'
#' @param dir character string, directory path where the
#' result files are located.
#' @param pattern character string, regex pattern for filenames to include.
#' @param rank_by which column to rank the data on, supplied as variable.
#' default: zscore
#' @param descending logical, whether ranking should be done from highest to
#' lowest value. default: TRUE
#' @param recursive logical, whether directories should be scanned recursively
#' for pathway files. default: TRUE
#'
#' @return data frame with IPA pathways
#' @export
#'
#' @importFrom magrittr %>%
#'
#' @examples
collate_pathways_ipa <- function(dir,
                                 pattern,
                                 rank_by = zscore,
                                 descending = TRUE,
                                 recursive = TRUE) {
  pathway_files <- list.files(
    dir,
    pattern = pattern,
    full.names = FALSE,
    recursive = recursive
  )

  ipa_pathways <- purrr::map_dfr(pathway_files, function(x) {
    # TODO add df type to ipa snakemake pipeline
    read_pathways_ipa(x, rank_by = rank_by, descending = descending) %>%
      dplyr::mutate(file = x)
  })
  return(ipa_pathways)
}

#' Parse json file generated by AmiGO analysis
#'
#' Jsonfile generated by http://amigo.geneontology.org/amigo preserves pathway
#' hierarchy. Resulting data frame will have a level column indicating
#' hierarchy level.
#'
#' @param filename character vector, path to json file containing pathway
#' analysis from AmiGO
#'
#' @return data frame
#' @export
#'
#' @importFrom magrittr %>%
#'
#' @examples
read_pathways_amigo <- function(filename) {
  json_list <- rjson::fromJSON(file = filename)

  # If the json file specification changes, this needs to be updated
  df <- purrr::map_dfr(json_list$overrepresentation$group, function(y) {
    if (length(y$result) == 3 &
      !is.list(y$result[[2]])) {
      data.frame(t(c(
        id = y$result$term$id,
        label = y$result$term$label,
        fold_enrichment = y$result$input_list$fold_enrichment,
        pvalue = y$result$input_list$pValue,
        level = y$result$term$level
      )))
    } else {
      purrr::map_dfr(y$result, function(x) {
        data.frame(t(c(
          id = x$term$id,
          label = x$term$label,
          fold_enrichment = x$input_list$fold_enrichment,
          pvalue = x$input_list$pValue,
          level = x$term$level
        )))
      })
    }
  }) %>%
    tidyr::drop_na() %>%
    dplyr::mutate(
      fold_enrichment = as.double(fold_enrichment),
      pvalue = as.double(pvalue),
      level = as.integer(level)
    )
  return(df)
}


#' Batch reading of AmiGO data from directory'
#'
#' @param dir character string, directory path where the
#' result files are located.
#' @param pattern character string, regex pattern for filenames to include.
#' @param rank_by which column to rank the data on, supplied as variable.
#' default: pvalue
#' @param filter_level_up_to integer, filter hierarchical levels for pathways.
#' Root hierarchy level is numbered with 0. Will filter levels up to the
#' specified hierarchy level, if NULL no filtering will be performed.
#' default: 0
#' @param recursive logical, whether directories should be scanned recursively
#' for pathway files. default: TRUE
#'
#' @return data frame
#' @export
#'
#' @examples
collate_pathways_amigo <- function(dir,
                                   pattern = "",
                                   rank_by = pvalue,
                                   filter_level_up_to = 0,
                                   recursive = TRUE) {
  pathway_files <- list.files(
    dir,
    pattern = pattern,
    full.names = TRUE,
    recursive = recursive
  )

  amigo_pathways <- purrr::map_dfr(pathway_files, function(x) {
    read_pathways_amigo(x) %>%
      dplyr::arrange(orientation(abs({{ rank_by }}))) %>%
      dplyr::mutate(pathway_rank = dplyr::row_number()) %>%
      dplyr::mutate(file = x)
  })

  if (!is.null(filter_level_up_to)) {
    amigo_pathways <- amigo_pathways  %>%
      dplyr::filter(level <= filter_level_up_to)
  }
  return(amigo_pathways)
}

#' Read dire data from excel file
#'
#' Result data from dire.dcode can be copied to excel while preserving tabular
#' formatting. The data should be kept as is from the webpage, the function
#' will take care of proper formatting.
#'
#' @param filename character string, file to read.
#' @param sheet_name character string, sheet name that contains the data.
#' default: Sheet1
#'
#' @return data frame
#' @export
#'
#' @importFrom magrittr %>%
#'
#' @examples
read_dire_xlsx <- function(filename, sheet_name = "Sheet1") {
  if (grepl(".xlsx", filename)) {
    df <- readxl::read_excel(filename, sheet = sheet_name) %>%
      dplyr::select(-`#`)
  } else {
    df <- readr::read_delim(filename) %>%
      dplyr::select(-`#`)
  }
  return(df)
}

#' Batch reading of dire data from directory
#'
#' Function will attempt to read all text and excel files in directory that
#' match the specified pattern. If other types of files match, it will throw
#' an error.
#'
#' @param dir character string, directory where dire data is
#' located.
#' @param pattern character string, regular expression to match the filenames
#' in specified directory, empty string will match all files.
#' default: empty string
#' @param sheet_name character string, for excel files the name of the sheet
#' that contains the dire data. default: "Sheet1"
#' @param recursive logical, whether directories should be scanned recursively
#' for pathway files. default: TRUE
#'
#' @return data frame
#' @export
#'
#' @importFrom magrittr %>%
#'
#' @examples
collate_pathways_dire <- function(dir,
                                  pattern = "",
                                  sheet_name = "Sheet1",
                                  recursive = TRUE) {
  empty_dire_df <- data.frame(
    `Transcription Factor` = character(0),
    Occurrence = numeric(0),
    Importance = numeric(0)
  )

  pathway_files <- list.files(
    dir,
    pattern = pattern,
    full.names = TRUE,
    recursive = recursive
  )

  dire_pathways <- purrr::map_dfr(pathway_files, function(x) {
    if (endsWith(x, "xlsx")) {
      tryCatch(
        {
          dire_df <- read_dire_xlsx(x, dire_sheet_name)
        },
        error = function(cond) {
          message("There were problems dire xlsx file, please check that the
          specifications are correct, skipping.")
          message(cond)
          return(empty_dire_df)
        }
      )
    } else {
      tryCatch(
        {
          dire_df <- read_data(x) %>%
            dplyr::select(-`#`) %>%
            dplyr::mutate(Occurrence = as.numeric(gsub("%", "", Occurrence)) / 100)
        },
        error = function(cond) {
          message("There were problems dire text file, please check that the
          specifications are correct, skipping.")
          message(cond)
          return(empty_dire_df)
        }
      )
    }
    dire_df <- dire_df %>%
      dplyr::mutate(file = x)
  })
  return(dire_pathways)
}

#' Filter pathways in a data frame
#'
#' @param pathway_data data frame with data for pathway analysis. Should include
#' a columns for enrichment/score, p-value and a pathway name
#' @param score_column name of score column, supplied as variable.
#' @param pvalue_column name of p-value column, supplied as variable.
#' @param rank_by which column to rank the data on, supplied as variable.
#' @param descending logical, whether ranking should be done from highest to
#' lowest value. default: TRUE
#' @param score_threshold double, return data subset that pass the score
#' threshold. Will compare the threshold against absolute values from score
#' column. default: 0
#' @param pvalue_threshold double, return data subset that pass the p-value
#' threshold.
#'
#' @return filtered pathway_data data frame
#' @export
#'
#' @importFrom magrittr %>%
#'
#' @examples
filter_pathways <- function(pathway_data,
                            score_column,
                            pvalue_column,
                            rank_by,
                            descending = TRUE,
                            score_threshold = 0,
                            pvalue_threshold = 0.05) {
  orientation <- rank_how(descending)

  pathway_data %>%
    dplyr::filter(abs({{ score_column }}) > score_threshold) %>%
    dplyr::filter({{ pvalue_column }} < pvalue_threshold) %>%
    dplyr::arrange(orientation(abs({{ rank_by }}))) %>%
    dplyr::mutate(pathway_rank = dplyr::row_number())
}

#' Read gene list from single column text file
#'
#' File shouldn't have a header.
#'
#' @param filename text file to read that contains single column with gene names
#' or IDs.
#'
#' @return character vector
#' @export
#'
#' @importFrom magrittr %>%
#'
#' @examples
read_gene_list_from_file <- function(filename) {
  gene_list <- readr::read_delim(filename,
    delim = "\t",
    col_names = c("SYMBOL")
  ) %>%
    dplyr::pull(SYMBOL)
  return(gene_list)
}
